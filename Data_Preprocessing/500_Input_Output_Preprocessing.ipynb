{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from itertools import product\n",
    "import sys, argparse, os\n",
    "import numpy as np\n",
    "from math import log, ceil\n",
    "from scipy.stats import multinomial, chi2\n",
    "from math import factorial\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = ['Bergsten_2013', \n",
    "               'Broughton_2013',\n",
    "               'Brown_2012', \n",
    "               'Cannon_2016_dna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_prefix = \"../training_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={'A':'1', 'T':'2', 'C':'3', 'G':'4', '-':'0', '?':'0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_list = []\n",
    "all_dists_list_cub = []\n",
    "all_dists_list_flatten = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH_NUM = 100\n",
    "SEQUENCE_LEN = 1000\n",
    "\n",
    "OUTPUT_DIST_NUM = int((BRANCH_NUM - 1) * BRANCH_NUM / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seq_data = np.zeros((BRANCH_NUM, SEQUENCE_LEN, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "for folder in folder_list:\n",
    "    file_path = os.path.join(training_dataset_prefix, folder)\n",
    "    files_list = os.listdir(file_path)\n",
    "    for file in files_list:\n",
    "        if file.find('.nex.treefile.dist') > 0:\n",
    "            file_base_name = file[0:file.find('.nex.treefile.dist')]\n",
    "#             print(\"******************\")\n",
    "#             print(file_base_name)            \n",
    "            #######################\n",
    "            # Input Processing !! #\n",
    "            #######################\n",
    "            seq_data_raw = open(os.path.join(file_path, file_base_name+'.nex'))\n",
    "            seq_data = seq_data_raw.readlines()[6:]\n",
    "            all_seq_data_list = []\n",
    "            all_seq_data = np.zeros((BRANCH_NUM,SEQUENCE_LEN,1))\n",
    "            for idx, line in enumerate(seq_data):\n",
    "                curr_line = line.split()\n",
    "                if len(curr_line) < 2:\n",
    "                    break\n",
    "#                 print('curr_line: ', curr_line)\n",
    "                seq_data_str = curr_line[1]\n",
    "#                 print(seq_data_str)\n",
    "#                 print('===============')\n",
    "#                 print(seq_data_str)\n",
    "                for item in dic:\n",
    "                    seq_data_str = seq_data_str.replace(item, dic[item])\n",
    "                #replace any remaining letter chars with 0                \n",
    "                seq_data_str = re.sub(r'[A-Z]', r'0', seq_data_str)\n",
    "#                 print((seq_data_str))\n",
    "                seq_data_list = list(seq_data_str)\n",
    "                if len(seq_data_list) > SEQUENCE_LEN:\n",
    "                    seq_data_list = seq_data_list[0:SEQUENCE_LEN-1]\n",
    "                all_seq_data[idx,0:len(seq_data_list),0] = seq_data_list\n",
    "            all_data_list.append(all_seq_data)\n",
    "#             print('all_seq_data.shape: ', all_seq_data.shape)\n",
    "\n",
    "            ########################\n",
    "            # Output Processing !! #\n",
    "            ########################\n",
    "            seq_dists_raw = open(os.path.join(file_path, file_base_name+'.nex.treefile.dist'))\n",
    "            species_number = int(seq_dists_raw.readline())\n",
    "            seq_dists = seq_dists_raw.readlines()[0:]            \n",
    "            all_seq_dists_cub = np.zeros((100,100,1))\n",
    "            all_seq_dists_flatten = []\n",
    "            for idx, line in enumerate(seq_dists):                \n",
    "                curr_line = line.split()\n",
    "                if len(curr_line) < 2:\n",
    "                    break\n",
    "\n",
    "                ### 3 dimension\n",
    "                dist_values_array_cub = np.array(curr_line[1:])\n",
    "                dist_values_array_cub = dist_values_array_cub.astype('float')\n",
    "                all_seq_dists_cub[idx,0:dist_values_array_cub.shape[0],0] = dist_values_array_cub\n",
    "                ### flatten\n",
    "                dist_values_array_flatten = np.array(curr_line[1:])\n",
    "                dist_values_array_flatten = dist_values_array_flatten[idx+1:species_number]\n",
    "                dist_values_array_flatten = dist_values_array_flatten.astype('float')\n",
    "                all_seq_dists_flatten = np.concatenate([all_seq_dists_flatten, dist_values_array_flatten])\n",
    "                \n",
    "            ### 3 dimension\n",
    "            all_dists_list_cub.append(all_seq_dists_cub)\n",
    "            \n",
    "            ### flatten \n",
    "            result = np.zeros((OUTPUT_DIST_NUM))\n",
    "            result[:all_seq_dists_flatten.shape[0]] = all_seq_dists_flatten\n",
    "            all_dists_list_flatten.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape:  (500, 100, 1000, 1)\n",
      "training_dists_cub.shape:  (500, 100, 100, 1)\n",
      "training_dists_flatten.shape:  (500, 4950)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.stack(all_data_list,axis=0)\n",
    "training_dists_cub = np.stack(all_dists_list_cub,axis=0)\n",
    "training_dists_flatten = np.stack(all_dists_list_flatten,axis=0)\n",
    "\n",
    "print('training_data.shape: ', training_data.shape)\n",
    "print('training_dists_cub.shape: ', training_dists_cub.shape)\n",
    "print('training_dists_flatten.shape: ', training_dists_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./output/training_data.npy', training_data)\n",
    "np.save('./output/training_dists_cub.npy', training_dists_cub)\n",
    "np.save('./output/training_dists_flatten.npy', training_dists_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
